import os
import json
from google.cloud import storage
from schemas import Case
from dotenv import load_dotenv

load_dotenv()

PROJECT_ID = os.getenv("GCP_PROJECT_ID", "tier3-ops-resolver") 
BUCKET_NAME = os.getenv("GCS_BUCKET_NAME", "tier3-ops-resolver-uploads")

def export_case_to_knowledge(case: Case, closure_note: str):
    """
    クローズされたケースをナレッジ化し、GCSにアップロードする。
    Vertex AI Searchの仕様に合わせ、json_dataフィールドに文字列化JSONを格納する。
    
    Output:
    1. FixCase (解決策) -> knowledge/fixcase/{case_id}.json
    2. Timeline (経緯) -> knowledge/timeline/{case_id}.jsonl
    """
    storage_client = storage.Client(project=PROJECT_ID)
    bucket = storage_client.bucket(BUCKET_NAME)
     
    try:
        
        root_cause = "See closure note"
        resolution = "See closure note"
        kb_title = case.title
        
        if case.latest_proposal and case.latest_proposal.closure_draft:
            draft = case.latest_proposal.closure_draft
            if hasattr(draft, "root_cause"):
                root_cause = draft.root_cause
                resolution = draft.resolution_steps
                kb_title = draft.knowledge_title or case.title
            elif isinstance(draft, dict):
                root_cause = draft.get("root_cause", "")
                resolution = draft.get("resolution_steps", "")
                kb_title = draft.get("knowledge_title", case.title)

        fixcase_inner = {
            "knowledge_type": "fix_case_card",
            "case_id": case.id,
            "title": kb_title,
            "symptom": {
                "what": case.title,
                "details": case.description,
                "environment": ["Generated from Closed Case"]
            },
            "primary_findings": {
                "summary": root_cause,
                "details": "Generated by Closer Agent"
            },
            "recommended_fixes": [
                {
                    "rank": 1,
                    "name": "Resolution Steps",
                    "why": "Accepted solution from closed case",
                    "procedure_outline": resolution.split("\n") if isinstance(resolution, str) else [str(resolution)],
                    "expected_result": "Case Solved"
                }
            ],
            "evidence": [
                {
                    "source": "Closure Note",
                    "signal": closure_note[:200] + "..." if len(closure_note) > 200 else closure_note,
                    "confidence": "High"
                }
            ],
            "diagnosis": {
                "most_likely_cause": root_cause,
                "notes": ["Automatically exported from OpsResolver"]
            }
        }

        fixcase_record = {
            "id": f"{case.id}-fixcase",
            "json_data": json.dumps(fixcase_inner, ensure_ascii=False)
        }

        blob_fix = bucket.blob(f"knowledge/fixcase/{case.id}.json")
        blob_fix.upload_from_string(
            json.dumps(fixcase_record, ensure_ascii=False),
            content_type="application/json"
        )
        print(f"✅ Exported FixCase: gs://{BUCKET_NAME}/knowledge/fixcase/{case.id}.json")

        
        timeline_records_str = ""
        
        for i, event in enumerate(case.timeline):
            ev_dict = event.dict() if hasattr(event, "dict") else event
            
            timeline_inner = {
                "knowledge_type": "timeline_event",
                "case_id": case.id,
                "case_title": case.title,
                "event_seq": i + 1,
                "date": ev_dict.get("timestamp", ""),
                "type": ev_dict.get("type", "general"),
                "actor": ev_dict.get("actor", "unknown"),
                "summary": str(ev_dict.get("message", ""))[:500] 
            }

            record = {
                "id": f"{case.id}-timeline-{i+1}",
                "json_data": json.dumps(timeline_inner, ensure_ascii=False)
            }
            
            timeline_records_str += json.dumps(record, ensure_ascii=False) + "\n"

        blob_timeline = bucket.blob(f"knowledge/timeline/{case.id}.jsonl")
        blob_timeline.upload_from_string(
            timeline_records_str,
            content_type="application/json"
        )
        print(f"✅ Exported Timeline: gs://{BUCKET_NAME}/knowledge/timeline/{case.id}.jsonl")
        
        return True

    except Exception as e:
        print(f"❌ Knowledge Export Error: {e}")
        import traceback
        traceback.print_exc()
        return False