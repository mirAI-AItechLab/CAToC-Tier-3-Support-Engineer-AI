# backend/main.py
import json
import uuid
import mimetypes
from typing import List, Optional, Union
from datetime import datetime, timedelta, timezone
from zoneinfo import ZoneInfo
from gmail_utils import send_reply 
from gmail_utils import get_gmail_service 
from schemas import ChatRequest
from dotenv import load_dotenv
from pathlib import Path
import os
import re

from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import vertexai
from vertexai.generative_models import GenerativeModel, Part
from google.cloud import firestore, storage
from pydantic import BaseModel
from knowledge_utils import search_knowledge_base 
from knowledge_exporter import export_case_to_knowledge
from gmail_utils import fetch_history_changes, process_single_message

from schemas import Case, CreateTriageRequest, AiProposal, EmailDraft, ApproveRequest
from schemas import ReplyIngestRequest, CloseRequest

load_dotenv

# --- è¨­å®š ---
PROJECT_ID = os.getenv("GCP_PROJECT_ID", "tier3-ops-resolver")
LOCATION = os.getenv("GCP_LOCATION", "us-central1")
MODEL_ID = os.getenv("GCP_MODEL_ID", "gemini-2.5-flash")
UPLOAD_BUCKET_NAME = os.getenv("GCS_BUCKET_NAME", "tier3-ops-resolver-uploads")

CURRENT_ACCOUNT = os.getenv("TARGET_EMAIL_ACCOUNT", "0sasurai0@gmail.com")

vertexai.init(project=PROJECT_ID, location=LOCATION)
db = firestore.Client(project=PROJECT_ID)

app = FastAPI(title="OpsResolver API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000","https://tier3-frontend-541297450514.us-central1.run.app"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
#  Helper Functions
# ==========================================
JST = ZoneInfo("Asia/Tokyo")

def now_utc_iso() -> str:
    return datetime.now(timezone.utc).isoformat()

def now_jst_iso() -> str:
    return datetime.now(JST).isoformat()

def clean_json_text(text: str) -> str:
    text = text.strip()
    if text.startswith("```json"):
        text = text[7:]
    elif text.startswith("```"):
        text = text[3:]
    if text.endswith("```"):
        text = text[:-3]

    start_idx = text.find("{")
    end_idx = text.rfind("}")
    
    if start_idx != -1 and end_idx != -1:
        text = text[start_idx : end_idx + 1]

    return text

def get_multimodal_content(text_prompt: str, gcs_uris: List[str]) -> List[Union[str, Part]]:
    """ãƒ†ã‚­ã‚¹ãƒˆã¨GCSä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Geminiå…¥åŠ›ç”¨Partã«å¤‰æ›ã™ã‚‹"""
    parts = [text_prompt]
    
    for uri in gcs_uris:
        ext = uri.split('.')[-1].lower()
        mime_type = None

        if ext in ['png']:
            mime_type = "image/png"
        elif ext in ['jpg', 'jpeg']:
            mime_type = "image/jpeg"
        elif ext in ['webp']:
            mime_type = "image/webp"
        elif ext in ['heic', 'heif']:
            mime_type = "image/heif"
            
        elif ext in ['mp4', 'mov', 'mpeg', 'mpg', 'avi']:
            mime_type = "video/mp4"
            
        elif ext in ['pdf']:
            mime_type = "application/pdf"
        elif ext in ['txt', 'log', 'csv', 'json', 'py', 'js', 'html', 'xml']:
            mime_type = "text/plain"

        if mime_type:
            print(f"ðŸ“Ž Attaching to Gemini: {uri} as {mime_type}")
            try:
                parts.append(Part.from_uri(uri=uri, mime_type=mime_type))
            except Exception as e:
                print(f"âš ï¸ Failed to attach part {uri}: {e}")
        else:
            print(f"â© Skipped unsupported file type: {uri} (ext: {ext})")
        
    return parts

def normalize_next_due(next_due_iso: Optional[str], now_jst: datetime, fallback_hours: int = 4) -> str:
    if not next_due_iso:
        return (now_jst + timedelta(hours=fallback_hours)).isoformat()

    s = next_due_iso.strip()
    if not (s.endswith("Z") or re.search(r"[+\-]\d{2}:\d{2}$", s)):
        s = s + "+09:00"

    try:
        dt = datetime.fromisoformat(s.replace("Z", "+00:00"))
    except Exception:
        return (now_jst + timedelta(hours=fallback_hours)).isoformat()

    dt_jst = dt.astimezone(JST)
    if dt_jst < now_jst:
        return (now_jst + timedelta(hours=fallback_hours)).isoformat()

    return dt_jst.isoformat()

def compute_waiting_for(next_status: str, action_type: Optional[str] = None) -> List[str]:
    """
    status/action ã‹ã‚‰ waiting_for ã‚’ä¸€è²«ã—ã¦æ±ºã‚ã‚‹
    """
    s = (next_status or "").upper()

    if s == "PROPOSED":
        return ["Engineer Approval"]
    if s in ["WAITING_CUSTOMER"]:
        return ["Customer Action"]
    if s in ["WAITING_INTERNAL", "VALIDATING"]:
        return ["Engineer Action"]
    if s == "CLOSED":
        return []

    return []

# ==========================================
#  1. Analyzer Agent (è§£æžæ‹…å½“)
# ==========================================
ANALYZER_INSTRUCTION = """
ã‚ãªãŸã¯ "OpsResolver"ï¼ˆTier-3 ã‚µãƒãƒ¼ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢AIï¼‰ã§ã™ã€‚
æä¾›ã•ã‚ŒãŸã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæƒ…å ±ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€è©³ç´°ã€ãƒ­ã‚°ã€ç”»åƒ/å‹•ç”»ãªã©ï¼‰ã‚’è§£æžã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸãƒˆãƒªã‚¢ãƒ¼ã‚¸ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

# æœ€å„ªå…ˆäº‹é …ï¼ˆé‡è¦ï¼‰
1) å‡ºåŠ›ã¯å¿…ãš **æœ‰åŠ¹ãªJSON**ï¼ˆãƒ‘ãƒ¼ã‚¹å¯èƒ½ï¼‰ã§ã‚ã‚‹ã“ã¨ï¼ˆMarkdownã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ä¸è¦ï¼‰
2) JSONã¯å¿…ãš `AiProposal` ã‚¹ã‚­ãƒ¼ãƒžã«ä¸€è‡´ã™ã‚‹ã“ã¨
3) `next_contact_due_proposal` ã¯ **Current Time ã‚’åŸºæº–**ã«è¨ˆç®—ã—ã€**éŽåŽ»æ—¥æ™‚ã«ã—ãªã„**ã“ã¨

# è§£æžæ–¹é‡
- ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰/ãƒ­ã‚°æ ¹æ‹ ã‹ã‚‰æ ¹æœ¬åŽŸå› ã‚’ä»®èª¬åŒ–ã—ã€æ¤œè¨¼ã‚³ãƒžãƒ³ãƒ‰ã‚„æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å…·ä½“çš„ã«ææ¡ˆã™ã‚‹
- æ–­å®šã§ã¯ãªãã€æ ¹æ‹ ï¼ˆãƒ­ã‚°ã®è¡Œ/ãƒ•ã‚¡ã‚¤ãƒ«/ç¾è±¡ï¼‰ã‚’æ·»ãˆã‚‹
- ä¸è¶³æƒ…å ±ãŒã‚ã‚Œã°å…·ä½“çš„ãªè³ªå•ã¨ã—ã¦åˆ—æŒ™ã™ã‚‹

# é¡§å®¢åã®ç‰¹å®šï¼ˆé‡è¦ï¼‰
- ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã®ç½²åã‚„åä¹—ã‚Šï¼ˆä¾‹: "ã€‡ã€‡æ ªå¼ä¼šç¤¾ã®ç”°ä¸­ã§ã™"ï¼‰ã‹ã‚‰é¡§å®¢åã‚’æŠ½å‡ºã— `detected_customer_name` ã«å…¥ã‚Œã‚‹
- ç‰¹å®šã§ããªã„å ´åˆã¯ null ã‚‚ã—ãã¯ "ã”æ‹…å½“è€…" ã¨ã™ã‚‹

# Next Contact Dueï¼ˆæ¬¡å›žé€£çµ¡æœŸé™ï¼‰ã®è¨ˆç®—ï¼ˆé‡è¦ï¼‰
å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä¸Žãˆã‚‰ã‚Œã‚‹ `Current Time`ï¼ˆç¾åœ¨æ™‚åˆ»ï¼‰ã‚’å¿…ãšåŸºæº–ã«ã—ã€
Severity/å„ªå…ˆåº¦ã«å¿œã˜ã¦ `next_contact_due_proposal` ã‚’è¨ˆç®—ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

- High / P1 (Critical): Current Time + 4 hours
- Medium / P2 (Error):  Current Time + 1 day
- Low / P3 (Warning):  Current Time + 3 days

ã€åˆ¶ç´„ã€‘
- `next_contact_due_proposal` ã¯å¿…ãš ISO8601ï¼ˆä¾‹: 2026-02-13T14:00:00+09:00ï¼‰ã§ timezone ä»˜ãã§å‡ºåŠ›ã™ã‚‹ã“ã¨
- `next_contact_due_proposal` ã¯ Current Time ã‚ˆã‚ŠéŽåŽ»ã«ã—ã¦ã¯ã„ã‘ãªã„
- è¿·ã£ãŸå ´åˆã¯ã€ŒCurrent Time + 4 hoursã€ã‚’æŽ¡ç”¨ã™ã‚‹ã“ã¨

# Windowsãƒ‘ã‚¹ã®æ‰±ã„ï¼ˆé‡è¦ï¼‰
ãƒ­ã‚°ã«Windowsãƒ‘ã‚¹ï¼ˆä¾‹: C:\\Windows\\Logs...ï¼‰ãŒå«ã¾ã‚Œã‚‹å ´åˆã€JSONæ–‡å­—åˆ—ã«å‡ºåŠ›ã™ã‚‹éš›ã¯ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’å¿…ãšäºŒé‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã™ã‚‹ã“ã¨ã€‚
- NG: "C:\\Windows\\System32"
- OK: "C:\\\\Windows\\\\System32"

# å‡ºåŠ›å½¢å¼ï¼ˆAiProposalã«æº–æ‹ ã—ãŸJSONã®ã¿ï¼‰
{
  "summary": "äº‹è±¡ã®æ¦‚è¦ï¼ˆ1-2è¡Œï¼‰",
  "detected_customer_name": "ç”°ä¸­ å¤ªéƒŽ",
  "hypotheses": [
    {"cause": "åŽŸå› ã®ä»®èª¬", "likelihood": "High/Medium/Low", "reasoning": "ç†ç”±ï¼ˆãƒ­ã‚°ã®xxè¡Œç›®ãªã©ï¼‰"}
  ],
  "missing_info": ["ä¸è¶³æƒ…å ±ãŒã‚ã‚Œã°ãƒªã‚¹ãƒˆåŒ–ï¼ˆå…·ä½“çš„ã«ï¼‰"],
  "evidence_pack": [
    {"type": "LOG_SNIPPET", "content": "æ ¹æ‹ ã®èª¬æ˜Ž", "source": "file_name or log_line", "is_verified": true}
  ],
  "next_action_plan": [
    {"type": "COMMAND", "title": "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å", "description": "è©³ç´°", "command": "å…·ä½“çš„ãªã‚³ãƒžãƒ³ãƒ‰"}
  ],
  "confidence_score": 0.9,
  "next_contact_due_proposal": "2026-02-13T14:00:00+09:00"
}
"""

def analyze_incident(title: str, description: str, logs: str, file_urls: List[str], history: str = "") -> AiProposal:
    model = GenerativeModel(model_name=MODEL_ID, system_instruction=ANALYZER_INSTRUCTION)
    
    search_query = title[:100]    
    knowledge_context = search_knowledge_base(
        query=search_query,
        filters=["fix_case_card", "timeline_event"]
    )
    print(f"ðŸ“š [RAG Result]:\n{knowledge_context[:500]}...\n(Total length: {len(knowledge_context)})")

    now_jst = datetime.now(JST)
    current_time_iso = now_jst.isoformat()

    base_prompt = f"""
    ã€å‰ææƒ…å ±ã€‘
    Current Time: {current_time_iso}

    ã€ã“ã‚Œã¾ã§ã®çµŒç·¯ (History)ã€‘
    ä»¥ä¸‹ã¯ã€ã“ã®ãƒã‚±ãƒƒãƒˆã«ãŠã‘ã‚‹éŽåŽ»ã®ã‚„ã‚Šã¨ã‚Šã§ã™ã€‚
    æ—¢ã«è©¦ã—ãŸç­–ã‚„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åå¿œã‚’è€ƒæ…®ã—ã¦ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚
    --------------------------------------------------
    {history if history else "ãªã—ï¼ˆæ–°è¦æ¡ˆä»¶ï¼‰"}
    --------------------------------------------------

    ã€ç¾åœ¨ã®ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã€‘
    Title: {title}
    Description: {description}
    Logs: {logs}
    
    ã€å‚è€ƒæƒ…å ±ï¼šéŽåŽ»ã®é¡žä¼¼ç—‡ä¾‹ãƒ»è§£æ±ºãƒ­ã‚° (RAG)ã€‘
    ä»¥ä¸‹ã®æƒ…å ±ã¯ã€éŽåŽ»ã«è§£æ±ºã—ãŸé¡žä¼¼æ¡ˆä»¶ã®è¨˜éŒ²ã§ã™ã€‚
    ç‰¹ã«ã€Žfix_case_cardã€ã«è¨˜è¼‰ã•ã‚ŒãŸè§£æ±ºç­–ã‚„åŽŸå› åˆ†æžã‚’å‚è€ƒã«ã€ä»Šå›žã®è§£æžã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
    
    {knowledge_context}
    """

    prompt_parts = get_multimodal_content(base_prompt, file_urls)
    
    try:
        response = model.generate_content(
            prompt_parts, 
            generation_config={"response_mime_type": "application/json"}
        )
        json_text = clean_json_text(response.text)
        data = json.loads(json_text)
        data["next_contact_due_proposal"] = normalize_next_due(
            data.get("next_contact_due_proposal"),
            now_jst=now_jst,
            fallback_hours=4,
        )

        return AiProposal(**data)

    except Exception as e:
        print(f"âŒ Analyzer Error: {e}")
        print(f"ðŸ’€ Raw Response (First 500 chars): {response.text[:500]}")

        return AiProposal(
            summary=f"Analysis failed: {e}",
            hypotheses=[], missing_info=[], evidence_pack=[], next_action_plan=[],
            confidence_score=0.0, next_contact_due_proposal=now_utc_iso()
        )

# ==========================================
#  2. Drafter Agent (ä»£ç­†æ‹…å½“)
# ==========================================
DRAFTER_INSTRUCTION = """
ã‚ãªãŸã¯ç†Ÿç·´ã®ã‚µãƒãƒ¼ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
è§£æžçµæžœã‚’å…ƒã«ã€é¡§å®¢ã¸ã®ä¸€æ¬¡è¿”ä¿¡ãƒ¡ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦: å®›åã¨ç½²åã€‘
- å®›åã«ã¯ã€è§£æžçµæžœã«å«ã¾ã‚Œã‚‹ `detected_customer_name` ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚ï¼ˆä¾‹: ç”°ä¸­ æ§˜ï¼‰
- ç½²åï¼ˆã‚ãªãŸã®åå‰ï¼‰ã®éƒ¨åˆ†ã«ã¯ã€å¿…ãš `[æ‹…å½“è€…å]` ã¨ã„ã†ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ç½®ã„ã¦ãã ã•ã„ã€‚
  ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãŒé€ä¿¡æ™‚ã«å®Ÿéš›ã®ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼åã«ç½®æ›ã—ã¾ã™ï¼‰

å‡ºåŠ›JSON:
{
  "to": "...",
  "subject": "...",
  "body": "ç”°ä¸­ æ§˜\n\nãŠä¸–è©±ã«ãªã£ã¦ãŠã‚Šã¾ã™...\n\n[æ‹…å½“è€…å]"
}

å‡ºåŠ›ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
{
  "to": "user@example.com",
  "subject": "ä»¶å...",
  "body": "æœ¬æ–‡...",
  "attachments": []
}

ã€è¦ä»¶ã€‘
- ä¸å¯§ã§å…±æ„Ÿçš„ãªæ—¥æœ¬èªžã‚’ä½¿ã†ã“ã¨ã€‚
- è§£æžçµæžœï¼ˆåŽŸå› ã‚„è§£æ±ºç­–ï¼‰ã‚’ã‚ã‹ã‚Šã‚„ã™ãä¼ãˆã‚‹ã“ã¨ã€‚
- è§£æ±ºç­–ãŒã‚ã‚‹å ´åˆã¯ã€æ‰¿èªã‚’æ±‚ã‚ã‚‹ã“ã¨ã€‚
"""

def draft_reply(proposal: AiProposal, sender_email: Optional[str], history: str = "") -> EmailDraft:
    model = GenerativeModel(model_name=MODEL_ID, system_instruction=DRAFTER_INSTRUCTION)
    
    search_query = proposal.summary[:100]    
    knowledge_context = search_knowledge_base(
        query=search_query,
        filters=["reply_draft", "policy_guard_card"]
    )
    print(f"ðŸ“š [RAG Result for Drafter]:\n{knowledge_context[:500]}...\n")

    context = proposal.model_dump_json()
    prompt = f"""
    ã€è§£æžçµæžœ JSONã€‘
    {context}
    
    ã€å®›å…ˆã€‘
    {sender_email or 'user@example.com'}    
    ã€å‚è€ƒæƒ…å ±ï¼šéŽåŽ»ã®è¿”ä¿¡ä¾‹ã¨ãƒãƒªã‚·ãƒ¼ (RAG)ã€‘
    ä»¥ä¸‹ã®æƒ…å ±ã‚’å…ƒã«ã€ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    ç‰¹ã«ã€Žpolicy_guard_cardã€ã®ãƒ«ãƒ¼ãƒ«ï¼ˆæ–­å®šç¦æ­¢ãªã©ï¼‰ã¯åŽ³å®ˆã—ã¦ãã ã•ã„ã€‚

    ã€ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ã€‘
    ä»¥ä¸‹ã‚’å‚ç…§ã—ã€æ–‡è„ˆã«æ²¿ã£ãŸè¿”ä¿¡ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    - åˆå›žã®å ´åˆã¯ä¸å¯§ãªæŒ¨æ‹¶ã‹ã‚‰å§‹ã‚ã‚‹ã€‚
    - æ—¢ã«ä½•åº¦ã‹ã‚„ã‚Šå–ã‚Šã—ã¦ã„ã‚‹å ´åˆã¯ã€æŒ¨æ‹¶ã‚’ç°¡æ½”ã«ã—ã€ã€Œã”ç¢ºèªã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€ã€Œå¼•ãç¶šãèª¿æŸ»ã—ã¾ã™ã€ã¨ã„ã£ãŸæ–‡è„ˆã«å¿œã˜ãŸè¡¨ç¾ã«ã™ã‚‹ã€‚
    --------------------------------------------------
    {history if history else "ãªã—ï¼ˆåˆå›žé€£çµ¡ï¼‰"}
    --------------------------------------------------
    
    {knowledge_context}
    """
    try:
        response = model.generate_content(
            prompt,
            generation_config={"response_mime_type": "application/json"}
        )
        json_text = clean_json_text(response.text)
        data = json.loads(json_text)
        return EmailDraft(**data)

    except Exception as e:
        print(f"âŒ Drafter Error: {e}")
        return EmailDraft(
            to=sender_email or "", 
            subject="Draft Error", 
            body="ãƒ‰ãƒ©ãƒ•ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        )

# ==========================================
#  3. Editor Agent (ç·¨é›†æ‹…å½“)
# ==========================================
EDITOR_INSTRUCTION = """
ã‚ãªãŸã¯ã€ç‰¹å®šã®ã‚µãƒãƒ¼ãƒˆã‚±ãƒ¼ã‚¹ã‚’æ‹…å½“ã™ã‚‹ "Copilot" (Editor Agent) ã§ã™ã€‚
ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‹ã‚‰ã®å…¥åŠ›ï¼ˆuser_queryï¼‰ã¨ã€ã“ã‚Œã¾ã§ã®çµŒç·¯ï¼ˆTimelineï¼‰ã«åŸºã¥ã„ã¦ã€ä»¥ä¸‹ã®å¯¾å¿œã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€å¯¾å¿œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã€‘
1. **ãƒ‰ãƒ©ãƒ•ãƒˆä¿®æ­£** (ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡):
   - ã€Œæ›¸ãç›´ã—ã¦ã€ã€Œä¸å¯§ã«ã€ç­‰ã®æŒ‡ç¤ºã«å¯¾ã—ã€`revised_reply_body` ã‚’å‡ºåŠ›ã™ã‚‹ã€‚
   
2. **ã‚¯ãƒ­ãƒ¼ã‚ºãƒ¡ãƒ¢ä½œæˆ/ä¿®æ­£** (è§£æ±ºè¦ç´„):
   - ã€Œã‚¯ãƒ­ãƒ¼ã‚ºãƒ¡ãƒ¢ã‚’æ›¸ã„ã¦ã€ã€Œè¦ç´„ã—ã¦è§£æ±ºã«ã—ã¦ã€ç­‰ã®æŒ‡ç¤ºã«å¯¾ã—ã€Timelineå…¨ä½“ã‚’è¦ç´„ã—ãŸè§£æ±ºè¨˜äº‹ã‚’ä½œæˆã—ã€`revised_closure_note` ã‚’å‡ºåŠ›ã™ã‚‹ã€‚
   - ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆä¾‹: 
     ã€äº‹è±¡ã€‘...
     ã€åŽŸå› ã€‘...
     ã€å¯¾å‡¦ã€‘...
   
3. **è³ªå•å›žç­”**:
   - ä¿®æ­£æŒ‡ç¤ºã§ãªã„å ´åˆã¯ã€`comment` ã®ã¿ã§å›žç­”ã™ã‚‹ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
{
  "revised_reply_body": "ä¿®æ­£å¾Œã®ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ (å¤‰æ›´ãªã—ãªã‚‰ null)",
  "revised_closure_note": "ä¿®æ­£å¾Œã®ã‚¯ãƒ­ãƒ¼ã‚ºãƒ¡ãƒ¢ (å¤‰æ›´ãªã—ãªã‚‰ null)",
  "comment": "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¸ã®å›žç­”ã€ã¾ãŸã¯å‡¦ç†å†…å®¹ã®è¦ç´„"
}
"""

@app.post("/cases/{case_id}/chat")
def chat_with_case(case_id: str, req: ChatRequest):
    doc_ref = db.collection("cases").document(case_id)
    doc = doc_ref.get()
    if not doc.exists:
        raise HTTPException(status_code=404, detail="Case not found")
    
    case = Case(**doc.to_dict())
    
    if not case.latest_proposal:
        raise HTTPException(status_code=400, detail="No proposal to edit")

    current_draft = "ï¼ˆãƒ‰ãƒ©ãƒ•ãƒˆæœªç”Ÿæˆï¼‰"
    if case.latest_proposal and case.latest_proposal.reply_draft:
        current_draft = case.latest_proposal.reply_draft.body

    current_closure = "ï¼ˆæœªè¨˜å…¥ï¼‰"    
    if case.latest_proposal.closure_note:
        current_closure = case.latest_proposal.closure_note
      
    history_lines = []
    for event in case.timeline:
        d = event.dict() if hasattr(event, "dict") else event        
        ts = d.get("timestamp", "")
        actor = d.get("actor", "UNKNOWN")
        evt_type = d.get("type", "EVENT")
        msg = d.get("message", "")        
        line = f"[{ts}] {actor} ({evt_type}): {msg}"
        history_lines.append(line)
    
    history_text = "\n".join(history_lines) if history_lines else "ï¼ˆå±¥æ­´ãªã—ï¼‰"    

    prompt = f"""
    
    ã€ã‚±ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ã€‘
    Title: {case.title}
    Description: {case.description}
    Customer: {case.customer_name}
    
    ã€ã“ã‚Œã¾ã§ã®å…¨çµŒç·¯ (Timeline History)ã€‘
    AIã¯ã“ã®å±¥æ­´ã‚’å‚ç…§ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€ŒéŽåŽ»ã¨åŒã˜ã«ã—ã¦ã€ç­‰ã®æŒ‡ç¤ºã«å¯¾å¿œã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚
    --------------------------------------------------
    {history_text}
    --------------------------------------------------    
    ã€ç¾åœ¨ã®ç·¨é›†å¯¾è±¡ã€‘
    [Email Draft]: {current_draft}
    [Closure Note]: {current_closure}
    
    ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‹ã‚‰ã®æŒ‡ç¤ºã€‘
    {req.user_query}
    
    ã€æŒ‡ç¤ºã€‘
    - ãƒ¡ãƒ¼ãƒ«ä¿®æ­£æŒ‡ç¤ºãªã‚‰ revised_reply_body ã‚’å‡ºåŠ›ã€‚
    - ã‚¯ãƒ­ãƒ¼ã‚ºãƒ¡ãƒ¢/è¦ç´„æŒ‡ç¤ºãªã‚‰ revised_closure_note ã‚’å‡ºåŠ›ã€‚
    - è³ªå•ãªã‚‰ comment ã®ã¿ã§å›žç­”ã€‚
    """
    
    model = GenerativeModel(model_name=MODEL_ID, system_instruction=EDITOR_INSTRUCTION)
    try:
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        data = json.loads(clean_json_text(response.text))
        reply_msg = data.get("comment", "å‡¦ç†å®Œäº†ã—ã¾ã—ãŸã€‚")
        
        updated = False

        new_body = data.get("revised_reply_body")
        if new_body and new_body.strip() and new_body != "null":
            if case.latest_proposal and case.latest_proposal.reply_draft:
                case.latest_proposal.reply_draft.body = new_body
                updated = True
                reply_msg = f"ãƒ¡ãƒ¼ãƒ«ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ä¿®æ­£ã—ã¾ã—ãŸã€‚\n({data.get('comment', '')})"

        new_note = data.get("revised_closure_note")
        if new_note and new_note.strip() and new_note != "null":
            if case.latest_proposal:
                case.latest_proposal.closure_note = new_note
                updated = True
                reply_msg = f"ã‚¯ãƒ­ãƒ¼ã‚ºãƒ¡ãƒ¢ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚\n({data.get('comment', '')})"

        if updated:
            case.updated_at = now_utc_iso()
            doc_ref.set(case.model_dump())

        return {
            "status": "success", 
            "reply": data.get("comment", "ä¿®æ­£ã—ã¾ã—ãŸã€‚"),
            "updated_case": case
        }
        
    except Exception as e:
        print(f"Chat Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==========================================
#  4. PM Agent (ç·¨é›†æ‹…å½“)
# ==========================================
PM_INSTRUCTION = """
ã‚ãªãŸã¯ã€ã‚µãƒãƒ¼ãƒˆçŠ¶æ³ã‚’ç›£è¦–ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ãƒ»ã‚ªãƒ–ã‚¶ãƒ¼ãƒãƒ¼ã§ã™ã€‚
ç¾åœ¨é€²è¡Œä¸­ã®ã™ã¹ã¦ã®ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆï¼ˆCaseä¸€è¦§ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æžã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€Œäº‹å®Ÿã€ã¨ã€Œæ•°å­—ã€ã«åŸºã¥ã„ã¦ç°¡æ½”ã«å›žç­”ã—ã¦ãã ã•ã„ã€‚

ã€å›žç­”ã®ãƒ«ãƒ¼ãƒ«ã€‘
- æŒ¨æ‹¶ã‚„è‡ªå·±ç´¹ä»‹ï¼ˆã€ŒãŠç–²ã‚Œæ§˜ã§ã™ã€ã€ŒPMã§ã™ã€ç­‰ï¼‰ã¯ä¸€åˆ‡ä¸è¦ã€‚
- çµè«–ã‹ã‚‰å…ˆã«è¿°ã¹ã‚‹ã€‚
- ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ãŒå¿…è¦ãªå ´åˆã¯ã€IDã¨æœŸé™ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç®‡æ¡æ›¸ãã«ã™ã‚‹ã€‚
- æ„Ÿæƒ…çš„ãªè¡¨ç¾ã¯é¿ã‘ã€å®¢è¦³çš„ãªåˆ†æžçµæžœã®ã¿ã‚’å‡ºåŠ›ã™ã‚‹ã€‚

ã€è©³ç´°æƒ…å ±ã®æ‰±ã„ã€‘
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç‰¹å®šã®ã‚±ãƒ¼ã‚¹IDï¼ˆä¾‹: case-xxxxxï¼‰ã«ã¤ã„ã¦è³ªå•ã—ã¦ãŠã‚Šã€ãã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆDetailed Contextï¼‰ãŒæä¾›ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ãã®ã€Œã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ï¼ˆHistoryï¼‰ã€ã‚’è¦ç´„ã—ã¦å›žç­”ã™ã‚‹ã“ã¨ã€‚

ã€åˆ¤æ–­åŸºæº–ã€‘
- `next_contact_due` ãŒéŽãŽã¦ã„ã‚‹ï¼ˆOverdueï¼‰æ¡ˆä»¶ã¯æœ€å„ªå…ˆã§è­¦å‘Šå¯¾è±¡ã¨ã™ã‚‹ã€‚
- `status` ãŒ `WAITING_INTERNAL` ã‚„ `PROPOSED` ã®ã¾ã¾æ”¾ç½®ã•ã‚Œã¦ã„ã‚‹æ¡ˆä»¶ã‚’ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦æ‰±ã†ã€‚
- ç‰¹å®šã®æ¡ˆä»¶ã«ã¤ã„ã¦ã®è³ªå•ã«ã¯ã€IDã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç…§åˆã—ã¦å›žç­”ã™ã‚‹ã€‚
"""

@app.post("/global/chat")
def global_chat(req: ChatRequest):
    docs = db.collection("cases").where("status", "!=", "CLOSED").stream()
    
    active_cases = []
    focused_case_details = ""
    target_case_id = None

    print(f"ðŸ•µï¸ PM Chat Query: {req.user_query}")
    match = re.search(r"(?:case-)?([a-f0-9]{8})", req.user_query, re.IGNORECASE)

    if match:
        extracted_hash = match.group(1).lower()
        target_case_id = f"case-{extracted_hash}"
        print(f"ðŸŽ¯ Target ID identified: {target_case_id} (from input:'{match.group(0)}')")
    else:
        print("ðŸ‘€ No specific Case ID detected in query.")

    for doc in docs:
        d = doc.to_dict()
        doc_id = d.get("id")

        if target_case_id and doc_id == target_case_id:
            print(f"âœ… Found detail data for: {target_case_id}")
            history_text = ""
            timeline = d.get("timeline", [])
            for event in timeline:
                ts = event.get("timestamp", "")
                actor = event.get("actor", "UNKNOWN")
                msg = event.get("message", "")
                evt_type = event.get("type", "")
                history_text += f"[{ts}] {actor} ({evt_type}): {msg}\n"
            if not history_text:
                history_text = "(Timeline is empty)"
            
            focused_case_details = f"""
            === ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸã‚±ãƒ¼ã‚¹ã®è©³ç´° (ID: {target_case_id}) ===
            Target ID: {target_case_id}
            Title: {d.get("title")}
            Description: {d.get("description")}
            Status: {d.get("status")}
            Priority: {d.get("priority")}
            Next Due: {d.get("next_contact_due")}
            
            ã€Timeline (History)ã€‘
            {history_text}
            =======================================================
            """

        active_cases.append({
            "id": d.get("id"),
            "title": d.get("title"),
            "status": d.get("status"),
            "priority": d.get("priority"),
            "waiting_for": d.get("waiting_for"),
            "next_due": d.get("next_contact_due"),
            "customer": d.get("customer_name")
        })
    
    from datetime import timedelta, timezone
    now_jst = datetime.now(timezone(timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S (JST)")
    
    context = json.dumps(active_cases, ensure_ascii=False, indent=2)
    prompt = f"""
    
    ã€å‰ææƒ…å ±ã€‘
    Current Time: {now_jst}  
    
    ã€ç¾åœ¨é€²è¡Œä¸­ã®æ¡ˆä»¶ãƒªã‚¹ãƒˆ (JSON)ã€‘
    {context}

    {focused_case_details}
    
    ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
    {req.user_query}
    
    ä¸Šè¨˜ã®æƒ…å ±ã‚’å…ƒã«ã€PMã¨ã—ã¦å›žç­”ã—ã¦ãã ã•ã„ã€‚
    æŒ‡å®šã•ã‚ŒãŸã‚±ãƒ¼ã‚¹ã®è©³ç´°æƒ…å ±ï¼ˆDetail Contextï¼‰ãŒã‚ã‚‹å ´åˆã¯ã€ãã®çµŒç·¯ï¼ˆTimelineï¼‰ã‚’è¦ç´„ãƒ»å‚ç…§ã—ã¦å›žç­”ã—ã¦ãã ã•ã„ã€‚    
    """

    model = GenerativeModel(model_name=MODEL_ID, system_instruction=PM_INSTRUCTION)
    try:
        response = model.generate_content(prompt)
        return {"status": "success", "reply": response.text}
    except Exception as e:
        print(f"PM Chat Error: {e}")
        return {"status": "error", "reply": "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ç¾åœ¨çŠ¶æ³ã®åˆ†æžã«å¤±æ•—ã—ã¾ã—ãŸã€‚"}

# ==========================================
#  5. Escalation Manager (ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤å®š)
# ==========================================
ESCALATION_INSTRUCTION = """
ã‚ãªãŸã¯ã€ã‚µãƒãƒ¼ãƒˆã‚»ãƒ³ã‚¿ãƒ¼ã®ã€Œã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ãƒžãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã€ã§ã™ã€‚
ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã®å†…å®¹ã¨éŽåŽ»ã®è§£æ±ºå±¥æ­´ï¼ˆRAGï¼‰ã‚’åˆ†æžã—ã€ã“ã®æ¡ˆä»¶ã‚’**ã€Œä»–éƒ¨ç½²ã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã¹ãã‹ã€**åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

ã€åˆ¤å®šåŸºæº–ã€‘
- æŠ€è¡“çš„ã«Tier-3ï¼ˆç¾åœ¨ï¼‰ã§è§£æ±ºå¯èƒ½ãªã‚‰ã€`target` ã¯ "None" ã¨ã™ã‚‹ã€‚
- éŽåŽ»ã®é¡žä¼¼äº‹ä¾‹ãŒç‰¹å®šã®ãƒãƒ¼ãƒ ï¼ˆSRE, Network, Dev, Billing, Legalãªã©ï¼‰ã§è§£æ±ºã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ãã®ãƒãƒ¼ãƒ åã‚’æŽ¨å¥¨ã™ã‚‹ã€‚
- è¿·ã£ãŸå ´åˆã¯ "None" (è‡ªå·±è§£æ±º) ã‚’å„ªå…ˆã™ã‚‹ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
{
  "target": "SRE Team",  // ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å…ˆã€ã¾ãŸã¯ "None"
  "reason": "éŽåŽ»ã®é¡žä¼¼ãƒ­ã‚°(Case-123)ã§DBå†èµ·å‹•ãŒå¿…è¦ã¨åˆ¤æ–­ã•ã‚Œã€SREã«ç§»ç®¡ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€‚"
}
"""

def consult_escalation_manager(title: str, description: str, logs: str) -> Optional[str]:
    query = f"{title} escalation transfer history"
    knowledge = search_knowledge_base(query, filters=["escalation"])
    
    prompt = f"""
    ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæƒ…å ±ã€‘
    Title: {title}
    Desc: {description}
    Logs: {logs[:1000]}
    
    ã€å‚è€ƒæƒ…å ±ï¼šéŽåŽ»ã®ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³/è§£æ±ºå®Ÿç¸¾ã€‘
    {knowledge}
    
    ä¸Šè¨˜ã«åŸºã¥ãã€ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å…ˆã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
    Tier-3ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢è‡ªèº«ã§è§£æ±ºã™ã¹ããªã‚‰ "None" ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
    """
    
    model = GenerativeModel(model_name=MODEL_ID, system_instruction=ESCALATION_INSTRUCTION)
    try:
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        data = json.loads(clean_json_text(response.text))
        
        target = data.get("target")
        if not target or target.upper() == "NONE":
            return None
            
        return target
    except Exception as e:
        print(f"âš ï¸ Escalation Manager Error: {e}")
        return None

# ==========================================
#  6. Closer Agent (ã‚¯ãƒ­ãƒ¼ã‚º & KBåŒ–æ‹…å½“)
# ==========================================
CLOSER_INSTRUCTION = """
ã‚ãªãŸã¯ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã®äº‹å¾Œåˆ†æžã‚’è¡Œã† "Closer Agent" ã§ã™ã€‚
æä¾›ã•ã‚ŒãŸã‚±ãƒ¼ã‚¹ã®å…¨å±¥æ­´ï¼ˆTimelineï¼‰ã¨æœ€çµ‚çŠ¶æ…‹ã‚’åˆ†æžã—ã€
ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ï¼ˆKBï¼‰ç™»éŒ²ç”¨ã®è¦ç´„ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›JSONã®è¦ä»¶ã€‘
- root_cause: æ ¹æœ¬åŽŸå› ï¼ˆæŠ€è¡“çš„ãªè¦å› ã‚’ç‰¹å®šã™ã‚‹ï¼‰
- resolution_steps: è§£æ±ºã«è‡³ã£ãŸå…·ä½“çš„ãªæ‰‹é †ï¼ˆç®‡æ¡æ›¸ãã€ã¾ãŸã¯æ”¹è¡ŒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ï¼‰
- prevention_measure: å†ç™ºé˜²æ­¢ç­–ï¼ˆã‚‚ã—ã‚ã‚Œã°ã€‚ãªã‘ã‚Œã°ã€Œç‰¹ã«ãªã—ã€ï¼‰
- knowledge_title: ä»Šå¾Œæ¤œç´¢ã—ã‚„ã™ã„ã€ç°¡æ½”ã‹ã¤å…·ä½“çš„ãªKBã‚¿ã‚¤ãƒˆãƒ«

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
{
  "root_cause": "...",
  "resolution_steps": "1. ...\\n2. ...",
  "prevention_measure": "...",
  "knowledge_title": "..."
}
"""

# ==========================================
#  End Points
# ==========================================

class PubSubMessage(BaseModel):
    message: dict
    subscription: str

@app.post("/webhook/gmail")
async def gmail_webhook(data: PubSubMessage):
    try:
        import base64
        import re
        
        pubsub_data = base64.b64decode(data.message['data']).decode('utf-8')
        json_data = json.loads(pubsub_data)
        email_address = json_data.get('emailAddress')
        
        print(f"ðŸ”” Push Notification received from: {email_address}")

        CURRENT_ACCOUNT = "0sasurai0@gmail.com"
        if email_address != CURRENT_ACCOUNT:
            return {"status": "ignored", "reason": "wrong_account"}

        print("ðŸ” Scanning for UNREAD messages...")
        
        service = get_gmail_service()
        query = "is:unread -from:me -label:OpsResolver_Done"        
        results = service.users().messages().list(
            userId='me', 
            q=query,
            maxResults=5 
        ).execute()
        
        messages = results.get('messages', [])
        
        if not messages:
            print("ðŸ“­ No unread messages found.")
            return {"status": "no_unread_messages"}

        print(f"ðŸ“¥ Found {len(messages)} unread messages. Processing...")

        for msg in messages:
            msg_id = msg['id']
            
            incident_data = process_single_message(msg_id)            
            if not incident_data:
                continue

            subject = incident_data['title']
            thread_id = incident_data.get("gmail_thread_id")
            gmail_message_id = incident_data.get("gmail_message_id")            
            
            print(f"ðŸ“¨ Processing: {subject}")
            
            existing_case = None
            if thread_id:
                docs = db.collection("cases").where("gmail_thread_id", "==", thread_id).limit(1).stream()
                for d in docs:
                    existing_case = Case(**d.to_dict())
                    print(f"ðŸ”— Found existing case by Thread ID: {existing_case.id}")
                    break
            
            match = re.search(r"\[Case:\s*(case-[a-f0-9]+)\]", subject, re.IGNORECASE)
            if match:
                extracted_id = match.group(1)
                print(f"ðŸ”— Found Case ID tag: {extracted_id}")
                doc = db.collection("cases").document(extracted_id).get()
                if doc.exists:
                    existing_case = Case(**doc.to_dict())

            if existing_case:

                thread_id = incident_data.get("gmail_thread_id")
                gmail_message_id = incident_data.get("gmail_message_id")
                if not getattr(existing_case, "gmail_thread_id", None) and thread_id:
                    existing_case.gmail_thread_id = thread_id
                if not getattr(existing_case, "gmail_message_id", None) and gmail_message_id:
                    existing_case.gmail_message_id = gmail_message_id
                
                print(f"ðŸ”„ Updating Case: {existing_case.id}")
                
                existing_case.timeline.append({
                    "id": f"evt-{uuid.uuid4().hex[:4]}",
                    "timestamp": now_utc_iso(),
                    "type": "REPLY_RECEIVED",
                    "actor": "USER",
                    "message": incident_data['description'],
                    "metadata": {"has_logs": bool(incident_data['file_urls'])}
                })
                
                history_text = ""
                for event in existing_case.timeline:
                    evt_dict = event.dict() if hasattr(event, "dict") else event
                            
                    ts = evt_dict.get("timestamp", "")
                    actor = evt_dict.get("actor", "UNKNOWN")
                    msg = evt_dict.get("message", "")
                            
                    history_text += f"[{ts}] {actor}: {msg}\n"

                combined_logs = f"""
                ã€ã“ã‚Œã¾ã§ã®çµŒç·¯ã€‘
                Title: {existing_case.title}
                Description: {existing_case.description}
                
                ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æœ€æ–°ã®è¿”ä¿¡ã€‘
                {incident_data['description']}
                
                ã€æ–°è¦æ·»ä»˜ãƒ­ã‚°/ãƒ•ã‚¡ã‚¤ãƒ«ã€‘
                {incident_data['file_urls']}
                """
                
                print("ðŸ§  Running Re-Analysis...")
                new_proposal = analyze_incident(
                    title=existing_case.title, 
                    description=existing_case.description, 
                    logs=combined_logs,
                    file_urls=incident_data['file_urls'],
                    history=history_text
                )
                
                new_draft = draft_reply(new_proposal, incident_data['sender_email'])
                new_proposal.reply_draft = new_draft
                
                existing_case.latest_proposal = new_proposal
                existing_case.status = "PROPOSED" 
                existing_case.waiting_for = compute_waiting_for("PROPOSED")
                if new_proposal.next_contact_due_proposal:
                    existing_case.next_contact_due = new_proposal.next_contact_due_proposal
                existing_case.updated_at = now_utc_iso()
                
                db.collection("cases").document(existing_case.id).set(existing_case.model_dump(), merge=True)
                print(f"âœ… Case {existing_case.id} Updated")

            else:
                print(f"ðŸ†• Creating NEW case: {subject}")
                thread_id = incident_data.get("gmail_thread_id")
                gmail_message_id = incident_data.get("gmail_message_id")

                print("DEBUG CREATE before pop:",
                      "thread_id=", incident_data.get("gmail_thread_id"),
                      "message_id=", incident_data.get("gmail_message_id"),
                      "saved_thread_id=", thread_id,
                      "saved_message_id=", gmail_message_id)

                incident_data.pop("gmail_thread_id", None)
                incident_data.pop("gmail_message_id", None)

                req = CreateTriageRequest(**incident_data)  
                proposal = analyze_incident(req.title, req.description, req.logs or "", req.file_urls)
                draft = draft_reply(proposal, req.sender_email)
                proposal.reply_draft = draft

                initial_timeline_event = {
                    "id": f"evt-{uuid.uuid4().hex[:4]}",
                    "timestamp": now_utc_iso(),
                    "type": "INGEST", 
                    "actor": "USER",
                    "message": incident_data['description'], 
                    "metadata": {
                        "subject": incident_data['title'],
                        "from": incident_data['sender_email'],
                        "files": len(incident_data['file_urls']),
                        "gmail_thread_id": thread_id,
                        "gmail_message_id": gmail_message_id,
                    }
                }          

                esc_target = consult_escalation_manager(req.title, req.description, req.logs or "")
                print(f"âš–ï¸ Escalation Judgment: {esc_target}")      

                print("DEBUG new_case fields:",
                      "case_id(planned)=", f"case-{uuid.uuid4().hex[:8]}",
                      "gmail_thread_id=", thread_id,
                      "gmail_message_id=", gmail_message_id)

                new_case = Case(
                    id=f"case-{uuid.uuid4().hex[:8]}",
                    title=req.title,
                    description=req.description,
                    status="PROPOSED",
                    priority="P1",
                    created_at=now_utc_iso(),
                    updated_at=now_utc_iso(),
                    next_contact_due=proposal.next_contact_due_proposal,
                    waiting_for=compute_waiting_for("PROPOSED"),
                    latest_proposal=proposal,
                    sender_email=req.sender_email,
                    sender_name=req.sender_name, 
                    customer_name=proposal.detected_customer_name, 
                    gmail_thread_id=thread_id,
                    gmail_message_id=gmail_message_id,
                    timeline=[initial_timeline_event],
                    escalation_target=esc_target,                      
                )
                db.collection("cases").document(new_case.id).set(new_case.model_dump())
                print(f"âœ… New Case Created: {new_case.id}")

        return {"status": "ok"}

    except Exception as e:
        print(f"âŒ Webhook Error: {e}")
        import traceback
        traceback.print_exc()
        return {"status": "error", "detail": str(e)}

@app.get("/cases", response_model=List[Case])
def list_cases():
    docs = db.collection("cases").order_by("updated_at", direction=firestore.Query.DESCENDING).stream()
    cases = []
    for doc in docs:
        cases.append(Case(**doc.to_dict()))
    return cases

@app.get("/cases/{case_id}", response_model=Case)
def get_case(case_id: str):
    doc_ref = db.collection("cases").document(case_id)
    doc = doc_ref.get()
    if not doc.exists:
        raise HTTPException(status_code=404, detail="Case not found")
    return Case(**doc.to_dict())

@app.post("/triage", response_model=Case)
def create_triage(req: CreateTriageRequest):
    print(f"ðŸš€ Triage started: {req.title} with {len(req.file_urls)} files")
    
    proposal = analyze_incident(
        req.title, 
        req.description, 
        req.logs or "", 
        req.file_urls 
    )
    
    draft = draft_reply(proposal, req.sender_email)
    proposal.reply_draft = draft
    esc_target = consult_escalation_manager(req.title, req.description, req.logs or "")

    new_case = Case(
        id=f"case-{uuid.uuid4().hex[:8]}",
        title=req.title,
        description=req.description,
        status="PROPOSED",
        priority="P1",
        created_at=now_utc_iso(),
        updated_at=now_utc_iso(),
        next_contact_due=proposal.next_contact_due_proposal,
        waiting_for=["Engineer Approval"],
        latest_proposal=proposal,
        customer_name=proposal.detected_customer_name,
        escalation_target=esc_target,         
    )
        
    db.collection("cases").document(new_case.id).set(new_case.model_dump())
    print(f"âœ… Case created in Firestore: {new_case.id}")

    return new_case

@app.post("/cases/{case_id}/approve", response_model=Case)
def approve_case(case_id: str, req: ApproveRequest):
    doc_ref = db.collection("cases").document(case_id)
    doc = doc_ref.get()
    if not doc.exists:
        raise HTTPException(status_code=404, detail="Case not found")

    target_case = Case(**doc.to_dict())
    
    if hasattr(req.approved_content, "model_dump"):
        content_data = req.approved_content.model_dump()
    elif hasattr(req.approved_content, "dict"):
        content_data = req.approved_content.dict()
    else:
        content_data = req.approved_content

    # =========================================================
    # ðŸ›¡ï¸ Guardrails (å®‰å…¨å¼)
    # =========================================================    
    if req.action_type == "SEND_REPLY":
        
        reply_to = target_case.latest_proposal.reply_draft.to
        reply_body = content_data.get("reply_body") or target_case.latest_proposal.reply_draft.body
        original_sender = target_case.sender_email 

        if original_sender and (reply_to != original_sender):
            
            if not reply_to.endswith("@neurorin.jp"):
                 print(f"ðŸ›¡ï¸ Blocked: Reply-to {reply_to} does not match original sender {original_sender}")
                 raise HTTPException(status_code=400, detail=f"Security Alert: You can only reply to the original sender ({original_sender}) or @neurorin.jp addresses.")
                 
        forbidden_words = ["ç¤¾å¤–ç§˜", "Confidential", "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯"]
        for word in forbidden_words:
            if word in reply_body:
                raise HTTPException(status_code=400, detail=f"Security Alert: Reply contains forbidden word: '{word}'")

        final_body = reply_body.replace("[æ‹…å½“è€…å]", req.operator_name or "ã‚µãƒãƒ¼ãƒˆæ‹…å½“")        
        print(f"ðŸš€ Approving & Sending reply to {reply_to}...")
        try:
            case_tag = f"[Case: {target_case.id}]"
            email_subject = f"{target_case.title} [Case: {target_case.id}]"

            print(
              "DEBUG approve threading:",
              "case_id=", target_case.id,
              "thread_id=", getattr(target_case, "gmail_thread_id", None),
              "message_id=", getattr(target_case, "gmail_message_id", None),
              "subject=", f"{target_case.title} [Case: {target_case.id}]",
              "to=", reply_to,
            )

            send_reply(
                to_email=reply_to,
                subject=email_subject,
                body=final_body,
                thread_id=target_case.gmail_thread_id,
                in_reply_to=target_case.gmail_message_id,
                references=target_case.gmail_message_id,
            )
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Email sending failed: {e}")

    next_status = content_data.get("next_status", "WAITING_CUSTOMER")
    target_case = Case(**doc.to_dict())
    target_case.status = next_status
    target_case.updated_at = now_utc_iso()

    if next_status == "WAITING_CUSTOMER":
        target_case.waiting_for = ["Customer Reply"]
    elif next_status == "WAITING_INTERNAL":
        target_case.waiting_for = ["Internal Action"]
    elif next_status == "VALIDATING":
        target_case.waiting_for = ["Validation Result"]
    elif next_status == "CLOSED":
        target_case.waiting_for = []
    else:
        target_case.waiting_for = []

    target_case.timeline.append({
        "id": f"evt-{uuid.uuid4().hex[:4]}",
        "timestamp": now_utc_iso(),
        "type": "HUMAN_APPROVE",
        "actor": "ENGINEER",
        "message": f"Action Approved. Status changed to {next_status}.",
        "metadata": content_data
    })

    doc_ref.set(target_case.model_dump(), merge=True)
    return target_case

@app.post("/cases/{case_id}/reply_ingest", response_model=Case)
def ingest_reply(case_id: str, req: ReplyIngestRequest):
    print(f"ðŸ”„ Processing reply for case: {case_id}")

    doc_ref = db.collection("cases").document(case_id)
    doc = doc_ref.get()
    if not doc.exists:
        raise HTTPException(status_code=404, detail="Case not found")
    
    target_case.timeline.append({
        "id": f"evt-{uuid.uuid4().hex[:4]}",
        "timestamp": now_utc_iso(),
        "type": "REPLY_RECEIVED",
        "actor": "USER",
        "message": req.reply_text,
        "metadata": {"has_logs": bool(req.new_logs)}
    })

    combined_logs = f"""
    [Original Logs] (Previous context)
    [User Reply] {req.reply_text}
    [New Logs Provided] {req.new_logs or "(No new logs)"}
    """

    target_case = Case(**doc.to_dict())
    
    new_proposal = analyze_incident(target_case.title, target_case.description, combined_logs, [])
    
    sender = target_case.latest_proposal.reply_draft.to if target_case.latest_proposal and target_case.latest_proposal.reply_draft else None
    new_draft = draft_reply(new_proposal, sender)
    new_proposal.reply_draft = new_draft

    target_case.latest_proposal = new_proposal
    target_case.status = "PROPOSED"
    target_case.waiting_for = compute_waiting_for("PROPOSED")
    target_case.updated_at = now_utc_iso()
    
    doc_ref.set(target_case.model_dump(), merge=True)
    return target_case

def generate_closure_summary(case: Case) -> dict:
    model = GenerativeModel(model_name=MODEL_ID, system_instruction=CLOSER_INSTRUCTION)
    
    timeline_logs = []
    for t in case.timeline:
        if isinstance(t, dict): d = t
        else: d = t.model_dump() if hasattr(t, "model_dump") else t.dict()
        timeline_logs.append(f"[{d.get('timestamp')}] {d.get('actor')}: {d.get('message')}")
    
    timeline_str = "\n".join(timeline_logs)
    
    prompt = f"Title: {case.title}\nDescription: {case.description}\nHistory:\n{timeline_str}\nLatest Analysis: {case.latest_proposal.model_dump_json() if case.latest_proposal else 'N/A'}"
    
    try:
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        return json.loads(clean_json_text(response.text))
    except Exception as e:
        print(f"Closer Error: {e}")
        return {"root_cause": "Error", "resolution_steps": "N/A", "prevention_measure": "N/A", "knowledge_title": "Error"}

@app.post("/cases/{case_id}/close", response_model=Case)
def close_case(case_id: str, req: CloseRequest):
    doc_ref = db.collection("cases").document(case_id)
    doc = doc_ref.get()
    if not doc.exists: raise HTTPException(status_code=404, detail="Case not found")
    target_case = Case(**doc.to_dict())

    print(f"ðŸ”’ Closing case: {case_id}")
    closure_data = generate_closure_summary(target_case)
    
    if target_case.latest_proposal:
        res_steps = closure_data.get("resolution_steps", "")
        if isinstance(res_steps, list): res_steps = "\n- ".join(res_steps)
        target_case.latest_proposal.closure_draft = {
            "root_cause": closure_data.get("root_cause", ""),
            "resolution_steps": res_steps, 
            "prevention_measure": closure_data.get("prevention_measure", "")
        }

    target_case.status = "CLOSED"
    target_case.updated_at = now_utc_iso()
    target_case.timeline.append({
        "id": f"evt-{uuid.uuid4().hex[:4]}", "timestamp": now_utc_iso(),
        "type": "STATUS_CHANGE", "actor": "ENGINEER",
        "message": f"Case Closed. Knowledge: {closure_data.get('knowledge_title')}", "metadata": closure_data
    })
    doc_ref.set(target_case.model_dump())  

    if req.publish_kb:
        print(f"ðŸ”„ Feedback Loop: Converting Case {case_id} to Knowledge...")
        export_case_to_knowledge(target_case, req.closure_note)

    return target_case